# Create CI/CD Pipelines
## CI/CD
CI/CD는 지속적 통합 및 지속적 배포 파이프라인으로 애플리케이션의 빌드, 테스트 및 배포를 자동화하여 개발과 운영 간의 격차를 해소한다.

여기서 CI는 개발자가 하루에 여러 번 공유 리포지토리에 코드를 통합해야 하는 개발 관행이다.
개발자가 코드를 push 하면 자동화된 빌드 과정을 통해 코드가 검증되고 문제가 있을 경우 조기에 발견할 수 있다. 여기서 코드를 분석하고 일련의 자동화된 테스트를 수행하게 된다.

CD는 테스트된 버전의 코드를 배포하는 과정이다.

CI/CD 도구로는 jenkins, argoCD 등이 존재한다.


### Jenkins
jenkins는 새로 만든 코드를 지속적으로 개발, 테스트 및 배포할 수 있는 지속적 통합 도구이다. 테스트와 빌드 프로세스를 제어하기 위해 CI 서버 역할을 하는 것이 바로 Jenkins이다.

#### 장점
간편한 설치 => Jenkins는 Windows, macOS 및 Linux 운영 체제용 패키지와 함께 실행할 준비가 된 독립형 자바 기반 프로그램

간편한 구성 => 오류 확인 및 기본 제공 도움말이 포함된 웹 인터페이스를 통해 쉽게 설정 및 구성 가능

플러그인 => 업데이트 센터에서 다양한 플러그인을 사용할 수 있으며 CI/CD 툴체인의 여러 도구와 통합

확장 가능 => 사용 가능한 플러그인 외에도 플러그인 아키텍처를 통해 Jenkins를 확장할 수 있어 거의 무한한 용도로 사용할 수 있는 옵션을 제공

분산 => Jenkins는 여러 머신에 작업을 쉽게 분산하여 여러 플랫폼에서 빌드, 테스트 및 배포 속도를 높일 수 있도록 지원

#### Jenkinsfile
코드를 통해 파이프라인의 단계를 정의할 수 있다. jenkins 대시보드에서 new item을 선택하고 pipeline 클릭을 통해 스크립트를 작성할 수 있다.

또한 jenkins 대시보드에서 credential 관리를 통해ㅔ global한 credential을 설정할 수 있다.

### Github Actions
github actions에서는 작업을 workflow라고 부른다. workflow는 yaml파일로 작성되고 하나 이상의 job을 포함하게 된다. 보통 repository의 특정 event에 의해 트리거되고 수행된다.

#### Event
workflow를 실행하도록 트리거하는 리포지토리의 특정 이벤트
#### Job
Runner에서 실행되는 Workflow의 step 집합

#### Step
step은 script나 action으로 구성
#### Action
자주 반복되는 작업에는 market에 있는 action을 주로 사용해서 단순화한다.
#### Runner
workflow를 실행하는 서버로 한 번에 하나의 작업을 실행한다.

### ArgoCD
Kubernetes를 위한 선언적 GitOps 지속적 배포 도구

# Monitoring, Log Management, and Data Visualisation
## 모니터링이란?

모니터링은 전체 인프라를 면밀히 주시하는 프로세스로. 사용하는 서버나, 서버의 모든 서비스, 애플리케이션, 리소스가 정상적으로 실행되고 있는지 확인하기 위해서 주로 사용한다.

### 모니터링을 하는 이유는?

⇒ 장애나 오류를 인지하고 예방하기 위해서 ! (devops팀은 문제를 감지하고 완화하기 까지의 과정을 최소화하기 위해 지속적으로 개선)

### 모니터링하는 방법

- 모든 서버에 수동으로 로그인하여 서비스 프로세스 및 리소스에 대한 모든 데이터를 확인
- 우리를 대신하여 서버에 로그인하고 데이터를 확인하는 스크립트 작성
- 모니터링 솔루션 활용
    - Prometheus, Zabbix, datadog,nagios 등..

### 모니터링 대상

- cpu 사용량
- 메모리 사용량
- 로그
- 등등..

## Nagios

인프라 모니터링 도구

오픈 소스 버전(Nagios Core)과 상용 버전이 존재

상용 버전으로는 Nagiox XI, Nagios Log Server 등이 있다.

## Prometheus

- 컨테이너와 마이크로서비스 기반 시스템뿐만 아니라 물리적, 가상 및 기타 서비스를 모니터링하는 데 도움이 되는 오픈 소스
- CNCF 프로젝트
- 간단한 텍스트 형식으로 메트릭을 쉽게 노출 가능하며, 데이터 모델은 key-value 형태로 레이블을 집계한 후 , Grafana같은 대시 보드 시스템에서 그래프로 쉽고 간단하게 Dashboard
- PromQL 쿼리 언어를 사용

![Untitled](https://github.com/MichaelCade/90DaysOfDevOps/blob/main/2022/Days/Images/Day78_Monitoring7.png)

보통 모니터링 도구는 각 서버에 클라이언트를 설치하고 해당 클라이언트가 메트릭 데이터를 수집해서 서버로 보내면 서버가 모니터링 상태를 보여주는 Push 방식을 취하지만

Prometheus는 Pull 방식을 사용하여 서버에 클라이언트가 떠 있으면 서버가 주기적으로 클라이언트에 접속해서 데이터를 가져오는 방식을 취한다.

** Helm

k8s 패키지 관리 도구로서 helm chart를 이용해서 복잡한 k8s 설정을 미리 정의할 수 있다.

즉, 변수 관리나 리소스를 하나의 패키지로 묶어서 관리할 수 있고 손쉽게 애플리케이션을 배포할 수 있다.

repository는 차트 저장소로 차트를 모아두고 공유하는 저장소이다.

```bash
kubectl expose deployment.apps/stable-prometheus-server --type="NodePort" --port 9090 --target-port=9090 --protocol="TCP" --name nodeport
```

```bash
minikube service nodeport --url
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/e1b21234-e4dc-43d0-a158-c0ef2cbba65a/b2b29f16-fd00-4f9f-aad5-7debe08768da/Untitled.png)

https://github.com/Terraform-Canvas/canvas-helm

## 로그 관리 및 집계

로그 집계는 다양한 서비스에서 애플리케이션 로그를 수집하고 태그를 지정하여 쉽게 검색할 수 있는 단일 대시보드에 저장하는 방법. APM에서 먼저 구축해야할 시스템 중 하나는 로그 집계.

로그 집계가 이제 로그를 생성하는 모든 곳에서 로그를 효율적으로 수집하고 장애가 다시 발생할 경우 쉽게 검색할 수 있도록 하는 좋은 로그 수집 플랫폼의 핵심

인기있는 오픈 소스 로그 집계 스택으로는 ELK가 존재.

ELK는 Elasticsearch, Logstash, Kibana로, 이것들의 구성 요소는 모든 서비스가 Logstash로 로그를 전송하고, Logstash는 애플리케이션이 방출하는 로그를 가져오는 구조이다.

하지만 Logstash는 자체적으로 로그를 저장하는 것이 아니라 텍스트 쿼리를 위한 효율적인 데이터베이스인 Elasticsearch에 저장하고 Elasticsearch는 Kibana로 결과를 노출하고 Kibana는 Elasticsearch에 연결하는 웹 서버로서 개발자나 팀의 다른 사람들이 관리자를 허용

즉, 관리자는 Kibana에 연결하고, Kibana는 사용자가 원하는 것과 일치하는 로그를 찾기 위해 Elasticsearch를 쿼리

++

프로메테우스가 좋은 모니터링 시스템이긴 하지만 결정적으로 클러스터링 구조를 지원하지 않기 때문에 확장성과 가용성 문제를 지니고 있다.

따라서 나온게 Thanos이며 여러개의 프로메테우스로 부터 매트릭을 조합해서 타노스에서 전체 프로메테우스의 메트릭을 볼 수 있도록 해주고, 수집된 메트릭을 스케일이 가능한 스토리지에 저장해서 특정 프로메테우스 인스턴스가 다운이 되더라도 그 인스턴스가 담당하는 메트릭을 조회할 수 있도록 해준다.

https://github.com/thanos-io/thanos

#### Logstash
로그와 이벤트 데이터를 수집합니다. 심지어 데이터를 구문 분석하고 변환

#### ElasticSearch
Logstash에서 변환된 데이터는 저장, 검색 및 색인

#### Kibana
Elasticsearch DB를 사용해 탐색, 시각화, 공유

### Fluentd
안정적인 로깅 파이프라인을 구축하는 데 적합한 네 가지 주요 기능을 갖는 오픈소스 통합 로깅 레이어

- JSON을 사용한 통합 로깅: Fluentd는 가능한 한 데이터를 JSON으로 구조화하려고 노력하고 이를 통해 여러 소스와 대상에 걸쳐 로그를 수집, 필터링, 버퍼링, 출력하는 등 로그 데이터 처리의 모든 측면을 통합할 수 있다. 엄격한 스키마를 강요하지 않고도 액세스할 수 있는 충분한 구조를 가지고 있기 때문에 JSON을 사용하면 다운스트림 데이터 처리가 훨씬 쉬워진다.

- 플러그 가능한 아키텍처: Fluentd는 커뮤니티가 기능을 확장할 수 있는 유연한 플러그인 시스템을 갖추고 있고 300개 이상의 커뮤니티 기여 플러그인이 수십 개의 데이터 소스를 수십 개의 데이터 출력에 연결하여 필요에 따라 데이터를 조작한다.

- 최소한의 리소스 필요: C와 Ruby의 조합으로 작성되어 최소한의 시스템 리소스를 필요로 하며 바닐라 인스턴스는 30~40MB의 메모리에서 실행되며 초당 13,000개의 이벤트를 처리할 수 있다.

- 내장된 안정성: 메모리 및 파일 기반 버퍼링을 지원하여 노드 간 데이터 손실을 방지하고 강력한 페일오버를 지원하며 고가용성을 위해 설정 가능


fluentd는 로그파일과 데이터베이스 기록, 타사 애플리케이션 로깅 데이터 유형을 허용하고 이를 수집, 처리하여 대상으로 로그를 전송할 수 있는 기능도 제공한다.

## FluentBit
Fluentd와 FluentBit는 입력 플러그인을 사용하여 데이터를 FluentBit 형식으로 변환한 다음, 출력 플러그인을 사용하여 엘라스틱서치와 같은 출력 대상이 무엇이든 출력 가능

Kubernetes의 FluentBit는 데몬셋으로 배포된다.

## EFK 스택
EFK는 ELK에서 로그 수집기를 FLuentD or FluentBit으로 대체한다.

## Grafana
Kibana의 folk로 시작되었으며, 당시 Kibana가 제공하지 않았던 메트릭, 즉 모니터링에 대한 지원을 제공하는 것이 목표!
무료 오픈 소스 데이터 시각화 도구로서 시스템 CPU, 메모리, 디스크 및 I/O 사용률과 같은 메트릭을 분석하고 시각화하는 데 적합하다.
