# Day70. CI/CD 파이프라인 개요
> CI/CD 파이프라인은 애플리케이션의 빌드. 테스트, 배포를 자동화하여 개발과 운영 간의 격차를 해소한다.

* 지속적 통합(CI)은 점진적인 코드 변경을 더 자주 그리고 안정적으로 수행할 수 있다. 트리거되는 자동화된 빌드 및 테스트 Workflow Step은 리포지토리에 병합되는 코드 변경 사항을 신뢰할 수 있도록 보장한다.

* 이점 : 수동으로 수행해야 하는 작업을 자동화하여 작은 문제가 메인 코드 베이스에 들어가기 전에 발견할 수 있다.

### CI
github과 같은 레포지토리에 코드를 push하면
**자동화된 빌드**를 통해 코드가 검증되므로 팀이나 프로젝트 소유자가 문제를 조기에 발견할 수 있다.
이후 **자동화된 테스트**를 완료하면 컴파일하여 레포지토리로 보낼 수 있다. (파이프라인의 CD 측면에 활용되는 모든 곳으로 보낼 수 있음)

* 자동화된 테스트의 예시
  * 단위테스트, 유효성 검사 테스트, 형식 테스트

### CD
테스트까지 마친 코드를 배포한다.

# Day71. Jenkins
| Jenkins: 새로 만든 코드를 지속적으로 개발, 테스트 및 배포할 수 있는 지속적 통합 도구

* 특징
  * 간편한 설치, 간편한 구성, 다양한 플러그인, 확장 가능성, 분산 가능(여러 머신에 작업을 분산하여 여러 플랫폼에서 빌드, 테스트, 배포 속도를 높일 수 있다.)

# Day72. Jenkins 실습
Jenkin를 사용해 CI 파이프라인 일부를 구성한다.
| Code Commit -> Build -> Test -> Release -> Deploy

Jenkins 파이프라인은 Jenkins파일이라는 텍스트 파일로 작성한다.


* helm으로 jenkins 배포하기 
  * 90daysofdevops의 명령을 진행하였지만 pod가 제대로 뜨지않아 아래 페이지를 참조하여 설치하였다.
  * https://github.com/jenkinsci/helm-charts/tree/main/charts/jenkins

# Day75. GitAction
> GitHub 내 어떤 이벤트(push, pull, merge ...)가 발생하면 해당 이벤트에 대해 정해진 동작을 실행하게 하는 도구
* 코드 저장소 내에서 .github/workflows 폴더 아래에 위치한 YAML 파일로 설정한다.


* **on** : 해당 워크플로우가 언제 실행되는지를 정의한다.
* **job** : 독립된 가상 머신(machine) 또는 컨테이너(container)에서 돌아가는 하나의 처리 단위를 의미한다.
모든 작업은 기본적으로 동시에 실행되며 필요 시 작업 간에 의존 관계를 설정하여 작업이 실행되는 순서를 제어할 수 있다.
  ```
  jobs:
    job1:
      # job1에 대한 세부 내용
    job2:
      # job2에 대한 세부 내용
    job3:
      # job3에 대한 세부 내용
  ```

* **steps** : 각 작업(job)이 하나 이상의 단계(step)로 이루어진다. 각 스텝엔 단순한 명령어나, shell script, action 을 실행할 수 있다.
  ```
  jobs:
    test:
      runs-on: ubuntu-latest
      steps:
        - uses: actions/checkout@v3 # action은 uses 키워드를 사용한다.
        - run: npm install # cmd는 run 키워드를 사용한다.
        - run: npm test
  ```

* **actions** : GitHub Actions에서 빈번하게 필요한 반복 단계를 재사용하기 용이하도록 제공되는 일종의 작업 공유 메커니즘
* [git action marketplace](https://github.com/marketplace?type=actions)



* git action에 대한 자세한 설명
https://www.daleseo.com/github-actions-basics/


# Day76. ArgoCD

```
# argocd 네임스페이스 생성
$ kubectl create namespace argocd

# 쿠버네티스 클러스터에 argocd 설치
$ kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
```

* 브라우저로 접근하기 위한 다음의 4가지 방식

서비스 타입을 LoadBalancer로 변경
서비스 타입을 NodePort로 변경
Ingress 생성 및 서비스 연결
Port Forward로 서비스 연결

```
$ kubectl port-forward svc/argocd-server -n argocd 8080:443
``` 

```
# 비밀번호를 확인하기 위한 명령어
$ kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d; echo
```

* 옵션 설명
* Application Name: App의 이름을 적습니다.
* Project: 프로젝트를 선택하는 필드입니다. 쿠버네티스의 namespace와 비슷한 개념으로 여러 App을 논리적인 project로 구분하여 관리할 수 있습니다.
* Sync Policy: Git 저장소의 변경 사항을 어떻게 sync할지 결정합니다. Auto는 자동으로 Git 저장소의 변경사항을 운영에 반영하고 Manual은 사용자가 버튼 클릭을 통해 직접 운영 반영을 해줘야 합니다.
* Repository URL: ArgoCD가 바라볼 Git 저장소를 의미합니다.
* Revision: Git의 어떤 revision (HEAD, master branch 등)을 바라 볼지 결정합니다.
* Path: Git 저장소에서 어떤 디렉토리를 바라 볼지 결정합니다. (dot(.)인 경우 root path를, 디렉토리 이름을 적으면 해당 디렉토리의 배포 정의서만 tracking 합니다.)
* Cluster: 쿠버네티스의 어느 클러스터에 배포할지를 결정합니다.
* Namespace: 쿠버네티스 클러스터의 어느 네임스페이스에 배포할지를 결정합니다.
* Directory Recurse: path아래의 디렉토리를 재귀적으로 모니터링하여 변경 사항을 반영합니다.

Auto-Sync 버튼을 활성화
* Prune Resources: 변경 사항에 따라 리소스를 업데이터할 때, 기존의 리소스를 삭제하고 새로운 리소스를 생성합니다. Job 리소스처럼 매번 새로운 작업을 실행해야 하는 경우 이 옵션을 사용합니다.
* Self Heal: 해당 옵션을 활성화 시키면 ArgoCD가 지속적으로 git repository의 설정값과 운영 환경의 값의 싱크를 맞출려고 합니다. 기본적으로 5초마다 계속해서 sync를 시도하게 됩니다. 

# Day77 모니터링 개요
- 모니터링의 방법 3가지
  - 모든 서버에 수동으로 로그인하여 서비스 및 프로세스 리소스 데이터 확인
  - 위 방법을 자동화할 스크립트 작성
  - 모니터링 솔루션 사용

- 모니터링의 목표
서버, 서비스, 인프라의 상태 파악

- 고려해야할 사항
어떤 리소스를 모니터링 할 것인고, 어떤 리소스를 모니터링 하지 않을 것인가

> 정보가 과다하면 모니터링 솔루션의 이점을 제대로 활용하기 어렵다. 시간을 들여 어떤 리소스를 모니터링할 것인지 파악해야한다.

* 지속적인 모니터링
  * 세 가지 주요 영역
    * 인프라 모니터링
    * 애플리케이션 모니터링
    * 네트워크 모니터링 

# Day78 모니터링 도구
| 모니터링 대상과 그 이유, 모니터링 제외 대상과 그 이유를 알아야한다는 점에서 PromQL을 알아야한다.

### pull/push 방식
* Push
  * 데이터를 가진 곳에서, 필요한 곳으로 보내준다.
  * 중앙집중형 / 중앙 모니터링 시스템이 데이터 수집 항목, 수집할 서버를 모두 관리한다.
  * Nagios, Zabbix

* Pull
  * 데이터가 필요한 곳에서, 가진 곳에 접속하여 데이터를 긁어간다.
  * 분산형 / 중앙시스템은 에이전트가 보내주는 데이터를 긁어갈 수만 있고, 어떤 데이터를 수집할 지 중앙에서 변경할 수 없다.
  * Prometheus, Datado, colletd

 수집 대상이 Auto-scaling 등으로 가변적일 경우, Push 방식이 Pull 방식보다 유리하다.
만약 새로운 수집 Host가 추가될 경우, Push방식에서는 Host가 Data-Backend로 수집데이터를 보내주기에, 전송된 데이터를 받기만 하면된다. 하지만 Pull 방식에선 Data-Backend가 수집 Host로 접속하여 데이터를 긁어가야 하기에, 중앙서버에서 pull해갈 Host/Service의 목록들을 관리하여야 한다.

수집 대상의 유연성 측면에서는 Pull 방식이 Push 방식보다 유리하다.
Pull 방식에서 중앙서버는 데이터를 수동적으로 긁어가기만 하기에, Pull system에서 Data-Backend는 언제든지 새로운 데이터(unplanned metrics)들을 수용할 수 있으며 모든 메트릭을 요청할 수 있도록 구현되어있다. 하지만 Push 방식에선 메트릭을 중앙에서 정의하고 에이전트로 푸시하는 구조이며, 새로운 메트릭 수용을 위해서는 중앙 서버에서 해당 변경사항을 반영해줘야한다.

보안 측면에서는 Push가 Pull보다 유리하다
Pull방식은 수집 대상 서버에서 중앙 폴러가 접근할 수 있는 포트, IP 등을 수신 대기해야 한다.

HA 측면에서 Pull이 Push 방식보다 유리하다.
Data-Backend에서 장애가 발생하더라도, Pull 방식에선 수집 Host에 영향이 없으나 Push 방식에선 데이터 전송 재시도 등 Host에 영향이 생긴다.

# Day79. 로그 관리 개요
모니터링과 로그 관리는 전체 통합 가시성을 위함이다.

* 로그 집계
  * 다양한 서비스에서 애플리케이션 로그를 수집하고 태그를 지정하여 쉽게 검색할 수 있는 단일 대시보드에 저장하는 방법
  * 애플리케이션 성능관리에서 가장 먼저 구축해야하는 시스템 중 하나
    * 애플리케이션 성능 관리는 데브옵스의 라이프사이클 중 하나이다
* 보안 및 로그 액세스
  로그에는 인증된 사용자만 보아야하는 토큰이나 민감 정보가 포함될 수 있다. 따라서 로그가 관리자에게만 표시되도록 한다. 인증 방법없이 kibana를 인터넷에 노출하지 않아야한다.


### ELK
오픈 소스 로그 집계 스택 : Elasticsearch, Logstash, Kibana
모든 서비스가 Logstash로 로그를 전송하면, Logstash는 로그 메세지에서 사용자가 **무엇을** **몇시에** 했다는 내용을 추출한다.
시간, 메세지, 사용자를 추출하여 **태그**로 변환하여 특정 사용자의 요청을 쉽게 검색할 수 있도록한다.

이때 태그는 텍스트 쿼리를 효율적으로 하기 위해 Elasticsearch에 저장한다. 원하는 결과를 쿼리 후에 Kibana에서 시각화한다.

* 문제 진단 방법
A: 오류코드 1234567이 나왔어
B: Kibana에 1234567 검색하여 해당 로그를 찾는다. 로그가 생성된 서비스와 시간을 파악하여 그 시간대의 로그를 분석해 원인을 찾는다.


# Day80. ELK 스택 실습
Beats/Logstash 데이터 수집
Elasticsearch 데이터 저장/처리
Kibana 분석/시각화

* 메트릭 vs 로그
https://www.metricfire.com/blog/prometheus-vs-elk/


# Day81. Fluentd vs FluentBit
* Fluentd의 네가지 주요 기능
  * JSON을 사용한 통합 로깅
  * 유연한 플러그인 시스템
  * 최소한의 리소스 요구(30MB~40MB의 메모리에서 초당 13,000개 이벤트 처리 가능)
  * 안정성, 메모리 및 파일 기반 버퍼링 지원하여 노드간 데이터 손실 방지

> 공식 문서: 최근 몇 년동안 클라우드 업체는 성능 및 호환성 이슈로 Fluentd에서 FluentBit로 전환했습니다.

# Day82. EFK 스택
컨테이너로 서비스 할 때는 로그를 기존 처럼 로그 파일에 기록하는 것이 아니라 표준 출력으로 남기고 EFK스택이나 ELK스택을 이용하여 수집, 저장, 가시화해야 한다.


* Elasticsearch
  * 수집된 로그를 저장하는 데이터베이스
  * 많은 양의 데이터를 보관하고 실시간으로 저장, 검색, 분석한다.
  * 특징 
    * 멀티테넌시
      * 데이터는 여러개로 분리된 인덱스들의 그룹으로 저장
      * 서로 다른 인덱스의 데이터를 하나의 질의로 검색하여 하나의 출력으로 도출가능하다.
    * 실시간 데이터 및 실시간 분석
      * 저장된 데이터는 검색에 사용되기 위해 별도의 재시작 / 갱신이 불필요하다.
      * 색인 작업이 완료됨과 동시에 바로 검색 가능하다.
      * 실시간 분석 / 검색은 데이터 증가량에 구애받지 않는다.
    * 고가용성
      * Elasticsearch는 하나 이상의 노드로 구성이 되고 각 노드는 1개 이상의 데이터 원본과 복사본을 서로 다른위치에 나누어 저장을하여 고가용성을 제공한다.
      * 항상 일정한 데이터 복사본의 개수를 유지하여 높은 가용성과 안정성을 보장한다.
      * 노드가 종료되거나 실행에 실패할 경우 다른 노드로 데이터를 이동한다.
    * 테이블과 스키마 대신에 JSON 형식으로 저장
    * 기본적으로 모든 필드를 색인 후에 JSON 형식으로 저장한다. JSON 구조로 인해 모든 레벨의 필드에 접근이 쉽고, 빠른 속도로 검색이 가능해진다.
    * JSON 문서를 URI로 명시, 이 문서를 처리하기 위해 HTTP 메소드를 이용한다.

* Fluentd 
  * 각 컨테이너 내의 어플리케이션이 콘솔에 남긴 로그를 수집, 변환 후 ES로 전송하는 툴
  * 데이터의 유실을 막기위해 메모리와 파일 기반 Buffer 시스템을 가지고 있다
  * Failover를 위한 HA 구성이 가능하다.

* Kibana
  *  Elasticsearch에 저장된 데이터를 이용하여 로그를 조회하고 검색하는 화면을 제공하는 툴
  * Kibana를 사용하여 웹 사이트 방문자를 표시할 수도 있고 트래픽을 실시간으로 볼 수도 있다.

* EFK 스택 Helm으로 설치하는 예제
https://happycloud-lee.tistory.com/258

# Day83 그라파나
* Kibana의 핵심 기능은 데이터 쿼리 및 분석
* Grafana는 Kibana의 folk로 시작되었으며, 당시 Kibana가 제공하지 않았던 메트릭, 즉 모니터링에 대한 지원을 제공하는 것이 목표였다.
* Grafana는 시스템 CPU, 메모리, 디스크 및 I/O 사용률과 같은 메트릭을 분석하고 시각화하는 데 적합

### 참고
https://coffeewhale.com/kubernetes/gitops/argocd/2020/02/10/gitops-argocd/
https://happycloud-lee.tistory.com/258
https://velog.io/@seunghyeon/0.-EFK-%EC%8A%A4%ED%83%9D%EA%B5%AC%EC%B6%95-EFK%EC%8A%A4%ED%83%9D